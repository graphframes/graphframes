name: Python CI
on: [push, pull_request]
jobs:
  test:
    strategy:
      fail-fast: false
      matrix:
        include:
          - spark-version: 3.5.7
            scala-version: 2.12
            python-version: "3.10"
            java-version: 11
          - spark-version: 4.0.1
            scala-version: 2.13
            python-version: "3.12"
            java-version: 17
          - spark-version: 4.1.0
            scala-version: 2.13
            python-version: "3.13"
            java-version: 17
    runs-on: ubuntu-latest
    env:
      # define Java options for both official sbt and sbt-extras
      JAVA_OPTS: -Xms2048M -Xmx2048M -Xss6M -XX:ReservedCodeCacheSize=256M -Dfile.encoding=UTF-8
      JVM_OPTS:  -Xms2048M -Xmx2048M -Xss6M -XX:ReservedCodeCacheSize=256M -Dfile.encoding=UTF-8
      SPARK_VERSION: ${{ matrix.spark-version }}
      SCALA_VERSION: ${{ matrix.scala-version }}
      PIP_REQUESTS_TIMEOUT: 100
    steps:
    - uses: actions/checkout@v6
    - uses: actions/setup-java@v5
      with:
        distribution: "zulu"
        java-version: "${{ matrix.java-version }}"
    - uses: actions/cache@v5
      with:
        path: |
          ~/.ivy2/cache
        key: sbt-ivy-cache-spark-${{ matrix.spark-version}}-scala-${{ matrix.scala-version }}
    - uses: actions/setup-python@v6
      with:
        python-version: ${{ matrix.python-version }}
    - name: Install and configure Poetry
      uses: snok/install-poetry@v1
      with:
        version: 2.1.3
        virtualenvs-create: true
        virtualenvs-in-project: false
        installer-parallel: true
    - name: Build Python package and its dependencies
      working-directory: ./python
      run: |
        poetry install --with=dev
        poetry run pip install pyspark[connect]==${{ matrix.spark-version }}
    - name: Code style
      working-directory: ./python
      run: |
        poetry run python -m black --check graphframes
        poetry run python -m flake8 graphframes
        poetry run python -m isort --check graphframes
    - name: Build jar
      working-directory: ./python
      run: |
        poetry run python dev/build_jar.py ${{ matrix.spark-version }}
    - name: Test
      working-directory: ./python
      run: |
        poetry run python -m pytest
    - name: Test SparkConnect
      env:
        SPARK_CONNECT_MODE_ENABLED: 1
      working-directory: ./python
      run: |
        poetry run python -m pytest
