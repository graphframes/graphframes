dist: trusty

group: travis_lts

cache:
  directories:
    - $HOME/.ivy2
    - $HOME/.sbt/launchers/
    - $HOME/.cache/spark-versions

language: scala

scala:
   - 2.11.8
   - 2.12.10

jdk:
   - oraclejdk8

env:
  global:
    - SCALA_VERSION=2.11.8

matrix:
  include:
    - env: PYSPARK_PYTHON=python2 SCALA_VERSION=2.11.8 SPARK_VERSION=2.4.4 SPARK_BUILD="spark-${SPARK_VERSION}-bin-hadoop2.7"
    - env: PYSPARK_PYTHON=python2 SCALA_VERSION=2.12.10 SPARK_VERSION=3.0.0-SNAPSHOT SPARK_BUILD="spark-${SPARK_VERSION}-bin-hadoop2.7"
    - env: PYSPARK_PYTHON=python3 SCALA_VERSION=2.11.8 SPARK_VERSION=2.4.4 SPARK_BUILD="spark-${SPARK_VERSION}-bin-hadoop2.7"
    - env: PYSPARK_PYTHON=python3 SCALA_VERSION=2.12.10 SPARK_VERSION=3.0.0-SNAPSHOT SPARK_BUILD="spark-${SPARK_VERSION}-bin-hadoop2.7"

install:
  - if [[ "${PYSPARK_PYTHON}" == "python2" ]]; then
      pyenv install -f 2.7.15 && pyenv global 2.7.15;
      python2 -m pip install --user -r ./python/requirements.txt;
    else
      pyenv install -f 3.6.3 && pyenv global 3.6.3;
      python3 -m pip install --user -r ./python/requirements.txt;
    fi

script:
  - sbt ++$TRAVIS_SCALA_VERSION -Dspark.version=$SPARK_VERSION "set test in assembly := {}" assembly
  - sbt ++$TRAVIS_SCALA_VERSION -Dspark.version=$SPARK_VERSION coverage test coverageReport

after_success:
  - bash <(curl -s https://codecov.io/bash)
